---
title: "Lab 14 - Advanced Visualization"
author: "Bree Bang-Jensen"
date: "2/12/2019"
output: html_document
---

```{r message = FALSE}
library(ggplot2)
library(dplyr)
library(ggcorrplot)
library(ggthemes)
library(stargazer)
```

## Maps

One of the most intuitive ways to present descriptive statistics or even substantive model outcomes is on a map. Let's use data from a prior CAPPP fellow to look at a simple example of how to use R to create a map. First, we load up her data, and some packages we are going to use. (You will need to install these packages, probably, before loading them.)

```{r}
library(maps)
library(mapdata)

map_data <- read.csv(file = "MapData.csv", 
                           header = TRUE, 
                           stringsAsFactors = FALSE, 
                           na.strings = ".")

View(map_data)
```

A brief aside: R is quickly becoming nearly as functional at producing maps as more traditional pieces of mapping software like ArcGIS. There are a number of packages, like tmap, ggmap, and sp, that use more traditional mapping approaches or build on google maps -- and are correspondingly complex. Know that they exist, in case your mapping needs are more complex than what we will cover today.

Our basic goal here is to create a map with outlines of entities (U.S. states, in this case), and then fill in those outlines with shades of color or patterns to signify density. We will start this process with three packages:

* The maps package contains the most basic outlines of continents, countries, states, and counties. (https://cran.r-project.org/web/packages/maps/maps.pdf)
* The mapdata package has even more outlines, at higher resolution! (https://cran.r-project.org/web/packages/mapdata/mapdata.pdf)
* Good 'ol ggplot, which has a built in function [map_data()] to operate with named map outlines from the maps and mapdata packages

First, a simple example:

```{r}
usa <- map_data("usa") # use ggplot to convert the map outline into a data frame of points
ggplot() + geom_polygon(data = usa, aes(x=long, y = lat, group = group)) + 
                        coord_fixed(1.3)
```

What is "coord_fixed"? It fixes the relationship between one unit in the y direction and one unit in the x direction. You might need to fiddle with this until the map looks "right" to you.

What is the "group" variable? It's about when ggplot "picks up the pen" when drawing. Take a look at the end of the "usa" dataset to see what I mean.

Now let's look at a map that draws in the individual U.S. states:

```{r}
states <- map_data("state")
state_plot <- ggplot(data = states) + 
              geom_polygon(aes(x = long, y = lat, fill = region, group = group), color = "white") + 
              coord_fixed(1.3) +
              guides(fill=FALSE)  # do this to leave off the color legend for now
state_plot
```

Here, I have asked ggplot to fill each state with a color by the "region" variable, which is just the name of the state. (Don't forget to think about your map as a data frame: you can easily subset the data frame and then plot to only give you states that you're interested in.)

Okay, cool: but how do we link the state-by-state data to this map of states? We need to append the state geographic data to the student's research data. The dplyr function left_join works for this, but there are many ways to accomplish this task:

```{r}
options(scipen = 999)
map_data_15 <- map_data %>% mutate(state = sapply(state, tolower)) %>% filter(Fifteen == 1)  #taking only 2015 and
                                    #making states lowercase

map_plot_data <- left_join(states, map_data_15, by = c("region" = "state"))

enviro_spending_plot <- ggplot(data = map_plot_data) + 
              geom_polygon(aes(x = long, y = lat, 
                               fill = Environmental_Spending, 
                               group = group), color = "white") + 
              coord_fixed(1.3) +
              theme_bw() 

enviro_spending_plot
```

Damn! This is definitely what we want, but right now California is so massive that it is drowning out all the variation in the other states. And the weird border and grid stuff looks, well, weird. And we probably want to clean up the legend. Let's adjust.

First, I make a theme, which I will apply to the plot. Making a custom theme and then applying it to several plots is a good, efficient thing to do.

```{r}
ditch_the_axes <- theme(
  axis.text = element_blank(),
  axis.line = element_blank(),
  axis.ticks = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.title = element_blank()
  )

# Clean up the map
enviro_spending_plot + ditch_the_axes

# Log transform the scale of the fill variable
enviro_spending_plot + ditch_the_axes + scale_fill_gradient(trans = "log10")

# Clean up the legend
enviro_spending_plot + ditch_the_axes + 
  scale_fill_gradient(trans = "log10", 
                      name = "Environmental\nSpending (in\nmillions)",
                      breaks = c(30000000, 300000000, 3000000000),
                      labels = c("30", "300", "3,000")) 
```

Reminder that we do not need to create -- and indeed should not create -- a title for this graph using ggplot's title function. We will create titles/captions for the graphs in LaTeX.

## Summary/descriptive statistics tables

When you think about what descriptive statistics to present, you need to think about what the reader will care about. So, you should probably never *merely* include the default descriptive statistics table from Stargazer. If you recall, it looks like this:

```{r}
load("R_WA_data.RData")

controls <- as.data.frame(cbind(WA_data$ideology, WA_data$wfd_distsize, WA_data$wfd_urban,   
                                WA_data$wfd_afam, WA_data$wfd_hisp, WA_data$wfd_forborn, 
                                WA_data$wfd_relincome, WA_data$wfd_college, 
                                WA_data$wfd_schoolage, WA_data$wfd_bcpct_const, 
                                WA_data$rep_pres_vote, WA_data$DsenRace, WA_data$open_seat))

colnames(controls) <- c("Ideology", "District Size", "Urbanization", 
                             "African American Pop.",
                             "Hispanic Pop.", "Foreign Born Pop.", 
                             "Relative Income in District",
                             "College Educated Pop.", "School Age Children", 
                             "Blue Collar Workers Pop.", 
                             "Republican Pres. Vote in District",
                             "State Senate Race in District", "Open Seat Race")

stargazer(controls,
          title = "Summary Statistics on Model Control Variables",
          type = "text", align = TRUE, no.space = TRUE)
```

That's great as far as it goes, but may not give enough important information about your variables to readers who are trying to make sense of your research project. On the other hand, it may give too much information about variables we don't care about. You can always customize this, or create your own tables in LaTeX. Remember: have a reason for showing us what you're showing us.

In that vein, you should think *smarter* than those first pass efforts. For example, what might readers want to know about this dataset? One thing I would be curious to know is what the profiles of the districts with the most and least female candidates looked like in terms of the control variables. Since the DV has a range of 0-4, I look at all the districts in either the 0 or the 3/4 categories, and compare them across the range of independent and control variables. This is a nice way to prefigure my regressions for this project.

```{r}
WA_data <- WA_data %>% mutate(wfd_distsize = log10(wfd_distsize)) %>% 
  mutate(rep_pres_vote = rep_pres_vote/100) %>%
  mutate(wfd_bcpct_const = wfd_bcpct_const/100) %>%
  mutate(wfd_college = wfd_college/100) %>%
  mutate(ideology = ideology + 1) 
  
zero_group <- WA_data %>% filter(DfemChalCanCount == 0)
four_group <- WA_data %>% filter(DfemChalCanCount == 4 | DfemChalCanCount == 3)

zero_variables <- as.data.frame(cbind(zero_group$DIfemCount, zero_group$ideology, zero_group$wfd_distsize, zero_group$wfd_urban, zero_group$wfd_afam, zero_group$wfd_hisp, zero_group$wfd_forborn, zero_group$wfd_relincome, zero_group$wfd_college, zero_group$wfd_schoolage, zero_group$wfd_bcpct_const, zero_group$rep_pres_vote))

four_variables <- as.data.frame(cbind(four_group$DIfemCount, four_group$ideology, four_group$wfd_distsize, four_group$wfd_urban, four_group$wfd_afam, four_group$wfd_hisp, four_group$wfd_forborn, four_group$wfd_relincome, four_group$wfd_college, four_group$wfd_schoolage, four_group$wfd_bcpct_const, four_group$rep_pres_vote))

var_names <- c("Female Incumbents", "Ideology", "District Size", "Urbanization", "African American Pop.", "Hispanic Pop.", "Foreign Born Pop.", "Relative Income in District", "College Educated Pop.", "School Age Children", "Blue Collar Workers Pop.", "Republican Pres. Vote")

colnames(zero_variables) <- var_names
colnames(four_variables) <- var_names

stargazer(zero_variables, four_variables,
          title = "Summary Statistics on Variables for Top and Bottom District Brackets (by fem. candidacy)",
          type = "text", align = TRUE, no.space = TRUE)
```

So, you could present these two tables next to each other, and let people look back and forth between the numbers. You could even build a table and put them side by side. These numbers are interesting, if you can get someone to spend that kind of time. But perhaps graphically we might find a better way.

First, an exercise on for loops!

```{r}
test <- seq(1, 10, by = 1)
sq <- NULL

for(i in 1:10){
  sq[i] <- test[i]*test[i]
  print(sq[i])
}

test
sq
i
```

Now, you try -- build a for loop that takes the first element of "test" and subtracts the number five from it, and so on, creating a new vector called "sums" which has ten elements.

```{r}

sums <- NULL

for(i in 1:10){
  sums[i] <- test[i]-5
}

sums

```

Alright, back to our visualizations!

```{r}
var_mean0 <- NULL
var_min0 <- NULL
var_max0 <- NULL
for (i in 1:length(zero_variables[1,])){
  var_mean0 <- append(var_mean0, mean(zero_variables[,i]))
  var_min0 <- append(var_min0, min(zero_variables[,i]))
  var_max0 <- append(var_max0, max(zero_variables[,i]))
}
#[R,C]

var_mean4 <- NULL
var_min4 <- NULL
var_max4 <- NULL
for (i in 1:length(four_variables[1,])){
  var_mean4 <- append(var_mean4, mean(four_variables[,i]))
  var_min4 <- append(var_min4, min(four_variables[,i]))
  var_max4 <- append(var_max4, max(four_variables[,i]))
}

zero_summ <- cbind(rep("zero", length.out = 12), signif(var_mean0, 2), 
                   signif(var_min0, 2), signif(var_max0, 2), var_names)
four_summ <- cbind(rep("three_four", length.out = 12), signif(var_mean4, 2), 
                   signif(var_min4, 2), signif(var_max4, 2), var_names)
dist_graphdata <- as.data.frame(rbind(zero_summ, four_summ))
colnames(dist_graphdata) <- c("group", "mean", "min", "max", "variable")

ggplot(dist_graphdata, 
                aes(y = group, x = mean, xmin = min, xmax = max)) +
                geom_point() +
                geom_point(size = 1.0) +
                geom_errorbarh() +
                labs(x = "Min, Mean, Max Values", 
                     y = "District Bracket") +
                theme_minimal() +
                scale_x_discrete(breaks = c(0,1,2,4)) +
                facet_wrap(~variable)
```

## Plotting summary statistics

```{r}
theme_set(theme_tufte())

ggplot(mpg, aes(manufacturer, cty)) + 
      geom_tufteboxplot() + 
      theme(axis.text.x = element_text(angle=65, vjust=0.6)) + 
      labs(title="Tufte Styled Boxplot", 
           subtitle="City Mileage grouped by Class of vehicle",
           caption="Source: mpg",
           x="Class of Vehicle",
           y="City Mileage") 
```

## Plotting a correlation matrix

```{r}
data(mtcars)
corr <- round(cor(mtcars), 1)

ggcorrplot(corr, hc.order = TRUE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="circle", 
           colors = c("#9970ab", "#f7f7f7", "#008837"),
           outline.col = "#f7f7f7",
           ggtheme=theme_tufte)
```
      
## Other food for thought
FLIPBOOKS. This is the coolest tool I've seen for teaching visualization in R, I love it so much. https://evamaerey.github.io/little_flipbooks_library/about/what_the_flipbook

Slope graphs are great. I've not made any myself, but you might want to try it, if you have data that compare a couple points in time: https://datascienceplus.com/creating-slopegraphs-with-r/
